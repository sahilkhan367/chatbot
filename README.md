# ğŸ¤– Sahil Khan â€“ AI Assistant (Multimodal RAG + Vision)

An AI-powered personal assistant that answers questions **as Sahil Khan** using a
**Retrieval-Augmented Generation (RAG)** pipeline and also understands images using
**YOLOv8 object detection**.

This project combines **LLMs, Vector Databases, Computer Vision, and Streamlit UI**
to create a smart, multimodal assistant.

---

## ğŸš€ Features

- ğŸ§  **Personal RAG Chatbot**
  - Answers questions using Sahil Khanâ€™s personal knowledge
  - Uses PDF-based knowledge with semantic search
  - Responds in first person (â€œIâ€, â€œmyâ€, â€œmeâ€)

- ğŸ“„ **PDF Knowledge Base**
  - Personal data stored in a PDF
  - Chunked, embedded, and indexed using FAISS

- ğŸ–¼ï¸ **Image Understanding**
  - Upload an image
  - Detect objects using YOLOv8
  - Explain detected objects using an LLM

- ğŸ”€ **Smart Routing**
  - Text questions â†’ RAG pipeline
  - Image-based queries â†’ Direct LLM (no RAG pollution)

- ğŸ’¬ **Chat Interface**
  - Streamlit chat UI
  - Chat history preserved during session
  - Thinking indicator for better UX

---

## ğŸ§© Architecture Overview



User
â”œâ”€â”€ Text Query â”€â”€â–º RAG (FAISS + PDF) â”€â”€â–º LLM â”€â”€â–º Answer
â””â”€â”€ Image Upload â”€â–º YOLOv8 â”€â–º Objects â”€â–º LLM â”€â–º Explanation




---

## ğŸ› ï¸ Tech Stack

- **LLM**: Ollama (Qwen2.5:0.5B)
- **Embeddings**: Ollama Embeddings
- **Vector DB**: FAISS
- **RAG Framework**: LangChain
- **Computer Vision**: YOLOv8 (Ultralytics)
- **Backend**: Python
- **UI**: Streamlit
- **Image Processing**: OpenCV, NumPy

---

## ğŸ“ Project Structure

LLM/
â”œâ”€â”€ app.py # Streamlit UI
â”œâ”€â”€ chatbot.py # RAG pipeline (LLM + FAISS + Prompt)
â”œâ”€â”€ object_detection.py # YOLOv8 object detection
â”œâ”€â”€ rag_backend.py # Vector DB creation script
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sahilkhan.pdf # Personal knowledge PDF
â”œâ”€â”€ vectorstore/ # FAISS index
â”œâ”€â”€ env/ # Python virtual environment
â””â”€â”€ README.md




â””â”€â”€ README.md


---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
1ï¸âƒ£ git clone <your-repo-url>
cd LLM

2ï¸âƒ£ Create virtual environment
python -m venv env
env\Scripts\activate   # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Install & run Ollama

Download: https://ollama.com

Pull model:

ollama pull qwen2.5:0.5b

5ï¸âƒ£ Create Vector Database
python rag_backend.py

6ï¸âƒ£ Run the app
streamlit run app.py

ğŸ§ª Example Use Cases
Text Query
Who are you?


â¡ï¸

My name is Sahil Khan, I am an IoT Engineer.

Image Upload

Upload a photo

YOLO detects objects (e.g., person, cell phone)

Assistant explains their real-world usage

ğŸ§  Design Decisions (Important)

RAG is only used for personal knowledge

Vision outputs are never sent to RAG

Prevents hallucinations and context pollution

Matches real-world multimodal AI architecture

ğŸ“Œ Limitations

Image explanations are based on object labels (no raw image vision model)

Chat history is session-based (not persisted)

UI follows Streamlit layout constraints

ğŸ”® Future Improvements

ğŸ–¼ï¸ Vision-language models (Qwen-VL / LLaVA)

ğŸ§  OCR + object detection

ğŸ’¾ Persistent chat memory

ğŸ¯ Bounding box visualization

ğŸŒ Web or mobile frontend